{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyperparameter Tuning - Classificação de Spam\n",
        "\n",
        "## Objetivo\n",
        "\n",
        "Otimizar hiperparâmetros do melhor modelo selecionado no notebook 02 para melhorar a performance.\n",
        "\n",
        "## Estratégia\n",
        "\n",
        "Usar RandomizedSearchCV para testar combinações aleatórias de hiperparâmetros:\n",
        "- Mais rápido que GridSearchCV\n",
        "- Geralmente encontra bons resultados\n",
        "- Testa espaço de busca maior\n",
        "\n",
        "## Modelo Base\n",
        "\n",
        "Utilizar **SVM (LinearSVC)** - melhor modelo identificado no notebook 02.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bibliotecas carregadas\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import time\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report\n",
        ")\n",
        "\n",
        "# Modelo e pré-processamento\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "print(\"Bibliotecas carregadas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Passo 1: Carregar Dados\n",
        "\n",
        "Carregar os dados processados do notebook 01.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dados carregados com sucesso!\n",
            "X_train_tfidf: (66758, 5000)\n",
            "X_test_tfidf: (16690, 5000)\n",
            "\n",
            "Mapeamento de labels: {'ham': np.int64(0), 'spam': np.int64(1)}\n",
            "Ham = 0, Spam = 1\n"
          ]
        }
      ],
      "source": [
        "# Carregar data splits\n",
        "splits_path = Path('artifacts/data_splits.joblib')\n",
        "\n",
        "if not splits_path.exists():\n",
        "    raise FileNotFoundError(\n",
        "        \"Artefatos do notebook 01 não encontrados. \"\n",
        "        \"Execute primeiro o notebook 01_exploratory_analysis.ipynb\"\n",
        "    )\n",
        "\n",
        "data_splits = joblib.load(splits_path)\n",
        "\n",
        "X_train_tfidf = data_splits['X_train_tfidf']\n",
        "X_test_tfidf = data_splits['X_test_tfidf']\n",
        "y_train = data_splits['y_train']\n",
        "y_test = data_splits['y_test']\n",
        "\n",
        "print(\"Dados carregados com sucesso!\")\n",
        "print(f\"X_train_tfidf: {X_train_tfidf.shape}\")\n",
        "print(f\"X_test_tfidf: {X_test_tfidf.shape}\")\n",
        "\n",
        "# Converter labels para numéricos\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Mapeamento para referência\n",
        "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "print(f\"\\nMapeamento de labels: {label_mapping}\")\n",
        "print(f\"Ham = {label_mapping.get('ham', 'N/A')}, Spam = {label_mapping.get('spam', 'N/A')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Passo 2: Configurar Modelo Base\n",
        "\n",
        "Configurar SVM (LinearSVC) como modelo base para otimização.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo base: SVM (LinearSVC)\n",
            "Parâmetros a otimizar: ['C', 'penalty', 'loss']\n",
            "\n",
            "Espaço de busca:\n",
            "  C: [0.1, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
            "  penalty: ['l2']\n",
            "  loss: ['squared_hinge']\n"
          ]
        }
      ],
      "source": [
        "# Modelo base: SVM (LinearSVC) - melhor modelo identificado no notebook 02\n",
        "best_model_name = \"SVM (LinearSVC)\"\n",
        "base_model = LinearSVC(random_state=42, max_iter=2000, dual=False)\n",
        "\n",
        "# Espaço de busca de hiperparâmetros para LinearSVC\n",
        "param_distributions = {\n",
        "    'C': [0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
        "    'penalty': ['l2'],  # l1 requer loss='squared_hinge' e dual=True, mas dual=False é mais rápido\n",
        "    'loss': ['squared_hinge']  # Única loss compatível com dual=False\n",
        "}\n",
        "\n",
        "print(f\"Modelo base: {best_model_name}\")\n",
        "print(f\"Parâmetros a otimizar: {list(param_distributions.keys())}\")\n",
        "print(f\"\\nEspaço de busca:\")\n",
        "print(f\"  C: {param_distributions['C']}\")\n",
        "print(f\"  penalty: {param_distributions['penalty']}\")\n",
        "print(f\"  loss: {param_distributions['loss']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando otimização de hiperparâmetros...\n",
            "Testando 20 combinações com 5-fold CV\n",
            "Isso pode levar alguns minutos...\n",
            "\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lucas-biason/Projetos/Projetos/ml-spam-classifier-api/notebooks/venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 6 is smaller than n_iter=20. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Otimização concluída em 11.71s (0.20 minutos)\n",
            "\n",
            "Melhores parâmetros encontrados:\n",
            "  penalty: l2\n",
            "  loss: squared_hinge\n",
            "  C: 0.5\n",
            "\n",
            "Melhor F1-Score (CV): 0.9848\n"
          ]
        }
      ],
      "source": [
        "# Configurar RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=base_model,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=20,  # Número de combinações a testar\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    scoring='f1',  # Métrica a otimizar\n",
        "    n_jobs=-1,  # Usar todos os cores\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Iniciando otimização de hiperparâmetros...\")\n",
        "print(f\"Testando {random_search.n_iter} combinações com 5-fold CV\")\n",
        "print(\"Isso pode levar alguns minutos...\\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# LinearSVC precisa de labels numéricos\n",
        "if 'SVM' in best_model_name or 'LinearSVC' in best_model_name:\n",
        "    y_train_model = y_train_encoded\n",
        "else:\n",
        "    y_train_model = y_train\n",
        "\n",
        "# Executar busca\n",
        "random_search.fit(X_train_tfidf, y_train_model)\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nOtimização concluída em {elapsed_time:.2f}s ({elapsed_time/60:.2f} minutos)\")\n",
        "print(f\"\\nMelhores parâmetros encontrados:\")\n",
        "for param, value in random_search.best_params_.items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "\n",
        "print(f\"\\nMelhor F1-Score (CV): {random_search.best_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Passo 4: Avaliar Modelo Otimizado\n",
        "\n",
        "Comparar performance do modelo otimizado com o modelo original.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COMPARAÇÃO: Baseline vs Otimizado\n",
            "\n",
            "================================================================================\n",
            "Métrica              Baseline        Otimizado       Melhoria       \n",
            "================================================================================\n",
            "Accuracy             0.9857          0.9865          +0.0007\n",
            "Precision            0.9830          0.9832          +0.0001\n",
            "Recall               0.9900          0.9912          +0.0013\n",
            "F1-Score             0.9865          0.9872          +0.0007\n",
            "================================================================================\n",
            "\n",
            "Melhoria no F1-Score: +0.07%\n"
          ]
        }
      ],
      "source": [
        "# Treinar modelo original (baseline)\n",
        "baseline_model = base_model.__class__(**base_model.get_params())\n",
        "if 'SVM' in best_model_name or 'LinearSVC' in best_model_name:\n",
        "    baseline_model.fit(X_train_tfidf, y_train_encoded)\n",
        "    y_pred_baseline = baseline_model.predict(X_test_tfidf)\n",
        "    y_pred_baseline = label_encoder.inverse_transform(y_pred_baseline)\n",
        "else:\n",
        "    baseline_model.fit(X_train_tfidf, y_train)\n",
        "    y_pred_baseline = baseline_model.predict(X_test_tfidf)\n",
        "\n",
        "# Predições do modelo otimizado\n",
        "y_pred_optimized = random_search.best_estimator_.predict(X_test_tfidf)\n",
        "if 'SVM' in best_model_name or 'LinearSVC' in best_model_name:\n",
        "    y_pred_optimized = label_encoder.inverse_transform(y_pred_optimized)\n",
        "\n",
        "# Métricas baseline\n",
        "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
        "baseline_precision = precision_score(y_test, y_pred_baseline, pos_label='spam', zero_division=0)\n",
        "baseline_recall = recall_score(y_test, y_pred_baseline, pos_label='spam', zero_division=0)\n",
        "baseline_f1 = f1_score(y_test, y_pred_baseline, pos_label='spam', zero_division=0)\n",
        "\n",
        "# Métricas otimizado\n",
        "optimized_accuracy = accuracy_score(y_test, y_pred_optimized)\n",
        "optimized_precision = precision_score(y_test, y_pred_optimized, pos_label='spam', zero_division=0)\n",
        "optimized_recall = recall_score(y_test, y_pred_optimized, pos_label='spam', zero_division=0)\n",
        "optimized_f1 = f1_score(y_test, y_pred_optimized, pos_label='spam', zero_division=0)\n",
        "\n",
        "# Comparação\n",
        "print(\"COMPARAÇÃO: Baseline vs Otimizado\\n\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'Métrica':<20} {'Baseline':<15} {'Otimizado':<15} {'Melhoria':<15}\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'Accuracy':<20} {baseline_accuracy:<15.4f} {optimized_accuracy:<15.4f} {optimized_accuracy - baseline_accuracy:+.4f}\")\n",
        "print(f\"{'Precision':<20} {baseline_precision:<15.4f} {optimized_precision:<15.4f} {optimized_precision - baseline_precision:+.4f}\")\n",
        "print(f\"{'Recall':<20} {baseline_recall:<15.4f} {optimized_recall:<15.4f} {optimized_recall - baseline_recall:+.4f}\")\n",
        "print(f\"{'F1-Score':<20} {baseline_f1:<15.4f} {optimized_f1:<15.4f} {optimized_f1 - baseline_f1:+.4f}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Melhoria percentual\n",
        "improvement = ((optimized_f1 - baseline_f1) / baseline_f1) * 100 if baseline_f1 > 0 else 0\n",
        "print(f\"\\nMelhoria no F1-Score: {improvement:+.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Passo 5: Salvar Modelo Otimizado\n",
        "\n",
        "Salvar o melhor modelo encontrado para uso no próximo notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Artefatos salvos:\n",
            "- Modelo otimizado: artifacts/optimized_model.joblib\n",
            "- Resultados: artifacts/hyperparameter_tuning_results.joblib\n"
          ]
        }
      ],
      "source": [
        "# Criar diretório para artefatos\n",
        "artifacts_dir = Path('artifacts')\n",
        "artifacts_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Salvar modelo otimizado\n",
        "optimized_model_path = artifacts_dir / 'optimized_model.joblib'\n",
        "joblib.dump(random_search.best_estimator_, optimized_model_path)\n",
        "\n",
        "# Salvar resultados da otimização\n",
        "optimization_results = {\n",
        "    'best_params': random_search.best_params_,\n",
        "    'best_cv_score': random_search.best_score_,\n",
        "    'test_accuracy': optimized_accuracy,\n",
        "    'test_precision': optimized_precision,\n",
        "    'test_recall': optimized_recall,\n",
        "    'test_f1': optimized_f1,\n",
        "    'baseline_f1': baseline_f1,\n",
        "    'improvement': improvement,\n",
        "    'model_type': best_model_name,\n",
        "    'optimization_date': datetime.now().isoformat()\n",
        "}\n",
        "\n",
        "results_path = artifacts_dir / 'hyperparameter_tuning_results.joblib'\n",
        "joblib.dump(optimization_results, results_path)\n",
        "\n",
        "print(\"Artefatos salvos:\")\n",
        "print(f\"- Modelo otimizado: {optimized_model_path}\")\n",
        "print(f\"- Resultados: {results_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusão do Hyperparameter Tuning\n",
        "\n",
        "### Resultados\n",
        "\n",
        "O modelo foi otimizado e os resultados estão disponíveis acima.\n",
        "\n",
        "### Próximo Passo\n",
        "\n",
        "**Notebook 04: Pipeline Final**\n",
        "- Treinar modelo final com todos os dados (sem split)\n",
        "- Exportar modelo e vetorizador para produção\n",
        "- Criar pipeline completo de inferência\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ML Spam Classifier",
      "language": "python",
      "name": "ml-spam-classifier"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
