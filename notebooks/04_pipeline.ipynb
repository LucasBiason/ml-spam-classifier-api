{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline Final - Classificação de Spam para Produção\n",
        "\n",
        "## Objetivo\n",
        "\n",
        "Treinar modelo FINAL para produção:\n",
        "- Usar 100% dos dados (sem train/test split)\n",
        "- Validar com cross-validation\n",
        "- Exportar artefatos completos para API\n",
        "\n",
        "## Configuração Final\n",
        "\n",
        "Baseado nos notebooks anteriores:\n",
        "- **Modelo**: SVM (LinearSVC) otimizado do notebook 03\n",
        "- **Features**: TF-IDF (5000 features)\n",
        "- **Vectorizer**: TfidfVectorizer do notebook 01\n",
        "- **Performance**: Métricas do notebook 03\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK - Bibliotecas carregadas\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "print(\"OK - Bibliotecas carregadas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Passo 1: Carregar Dados Completos\n",
        "\n",
        "Carregar todos os dados (sem split) para treinar modelo final.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset completo: 83,448 emails\n",
            "Colunas: ['label', 'message']\n",
            "\n",
            "X_full: 83,448 mensagens\n",
            "y_full: 83,448 labels\n",
            "\n",
            "Distribuição de classes:\n",
            "label\n",
            "spam    43910\n",
            "ham     39538\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Carregar dataset completo\n",
        "data_path = Path('data/emails.csv')\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "print(f\"Dataset completo: {len(df):,} emails\")\n",
        "print(f\"Colunas: {df.columns.tolist()}\")\n",
        "\n",
        "# Separar features e target\n",
        "X_full = df['message']\n",
        "y_full = df['label']\n",
        "\n",
        "print(f\"\\nX_full: {len(X_full):,} mensagens\")\n",
        "print(f\"y_full: {len(y_full):,} labels\")\n",
        "print(f\"\\nDistribuição de classes:\")\n",
        "print(y_full.value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Passo 2: Carregar Vetorizador e Modelo Otimizado\n",
        "\n",
        "Carregar o vetorizador TF-IDF do notebook 01 e o modelo otimizado do notebook 03.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vetorizador TF-IDF carregado!\n",
            "Modelo otimizado carregado!\n",
            "Modelo: SVM (LinearSVC)\n",
            "F1-Score esperado: 0.9872\n"
          ]
        }
      ],
      "source": [
        "# Carregar vetorizador do notebook 01\n",
        "vectorizer_path = Path('artifacts/tfidf_vectorizer.joblib')\n",
        "if not vectorizer_path.exists():\n",
        "    raise FileNotFoundError(\"Vetorizador não encontrado. Execute o notebook 01 primeiro.\")\n",
        "\n",
        "vectorizer = joblib.load(vectorizer_path)\n",
        "print(\"Vetorizador TF-IDF carregado!\")\n",
        "\n",
        "# Carregar modelo otimizado do notebook 03\n",
        "optimized_model_path = Path('artifacts/optimized_model.joblib')\n",
        "if not optimized_model_path.exists():\n",
        "    raise FileNotFoundError(\"Modelo otimizado não encontrado. Execute o notebook 03 primeiro.\")\n",
        "\n",
        "optimized_model = joblib.load(optimized_model_path)\n",
        "print(\"Modelo otimizado carregado!\")\n",
        "\n",
        "# Carregar resultados da otimização\n",
        "tuning_results_path = Path('artifacts/hyperparameter_tuning_results.joblib')\n",
        "if tuning_results_path.exists():\n",
        "    tuning_results = joblib.load(tuning_results_path)\n",
        "    print(f\"Modelo: {tuning_results.get('model_type', 'Unknown')}\")\n",
        "    print(f\"F1-Score esperado: {tuning_results.get('test_f1', 0):.4f}\")\n",
        "else:\n",
        "    tuning_results = {}\n",
        "    print(\"Resultados da otimização não encontrados.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Passo 3: Treinar Modelo Final\n",
        "\n",
        "Treinar modelo final com 100% dos dados usando os melhores hiperparâmetros encontrados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vetorizando todos os dados...\n",
            "Shape final: (83448, 5000)\n",
            "\n",
            "Treinando modelo final com 100% dos dados...\n",
            "Isso pode levar alguns minutos...\n",
            "Modelo LinearSVC treinado com labels numéricos\n",
            "Mapeamento: {'ham': np.int64(0), 'spam': np.int64(1)}\n",
            "\n",
            "Modelo final treinado em 1.45s\n",
            "Total de amostras de treino: 83,448\n"
          ]
        }
      ],
      "source": [
        "# Vetorizar todos os dados\n",
        "print(\"Vetorizando todos os dados...\")\n",
        "X_full_tfidf = vectorizer.transform(X_full)\n",
        "print(f\"Shape final: {X_full_tfidf.shape}\")\n",
        "\n",
        "# Treinar modelo final com todos os dados\n",
        "print(\"\\nTreinando modelo final com 100% dos dados...\")\n",
        "print(\"Isso pode levar alguns minutos...\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Criar novo modelo LinearSVC com os mesmos parâmetros do otimizado\n",
        "final_model = LinearSVC(**optimized_model.get_params())\n",
        "\n",
        "# LinearSVC precisa de labels numéricos\n",
        "label_encoder = LabelEncoder()\n",
        "y_full_encoded = label_encoder.fit_transform(y_full)\n",
        "final_model.fit(X_full_tfidf, y_full_encoded)\n",
        "\n",
        "print(\"Modelo LinearSVC treinado com labels numéricos\")\n",
        "print(f\"Mapeamento: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\")\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nModelo final treinado em {training_time:.2f}s\")\n",
        "print(f\"Total de amostras de treino: {len(y_full):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Passo 4: Validação com Cross-Validation\n",
        "\n",
        "Validar modelo final usando cross-validation para garantir robustez.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executando 5-fold cross-validation...\n",
            "Isso pode levar alguns minutos...\n",
            "\n",
            "Resultados do Cross-Validation:\n",
            "  F1-Score médio: 0.9856 (+/- 0.0014)\n",
            "  Scores individuais: [0.98616937 0.98634019 0.9847756  0.986056   0.98477446]\n",
            "  Min: 0.9848\n",
            "  Max: 0.9863\n"
          ]
        }
      ],
      "source": [
        "# Cross-validation com F1-Score\n",
        "print(\"Executando 5-fold cross-validation...\")\n",
        "print(\"Isso pode levar alguns minutos...\\n\")\n",
        "\n",
        "# Cross-validation com labels numéricos (LinearSVC)\n",
        "cv_scores = cross_val_score(\n",
        "    final_model,\n",
        "    X_full_tfidf,\n",
        "    y_full_encoded,\n",
        "    cv=5,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"Resultados do Cross-Validation:\")\n",
        "print(f\"  F1-Score médio: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "print(f\"  Scores individuais: {cv_scores}\")\n",
        "print(f\"  Min: {cv_scores.min():.4f}\")\n",
        "print(f\"  Max: {cv_scores.max():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Passo 5: Exportar Artefatos para Produção\n",
        "\n",
        "Salvar modelo final, vetorizador e metadados para uso na API.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Modelo final salvo: artifacts/best_model_temp.joblib\n",
            "✓ Vetorizador salvo: artifacts/tfidf_vectorizer.joblib\n",
            "✓ Label encoder salvo: artifacts/label_encoder.joblib\n",
            "✓ Metadados salvos: artifacts/metadata.joblib\n",
            "\n",
            "================================================================================\n",
            "ARTEFATOS EXPORTADOS PARA PRODUÇÃO\n",
            "================================================================================\n",
            "1. best_model_temp.joblib (modelo treinado)\n",
            "2. tfidf_vectorizer.joblib (vetorizador TF-IDF)\n",
            "3. label_encoder.joblib (encoder de labels)\n",
            "4. metadata.joblib (informações do modelo)\n"
          ]
        }
      ],
      "source": [
        "# Criar diretório para modelos finais\n",
        "models_dir = Path('artifacts')\n",
        "models_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# 1. Salvar modelo final\n",
        "final_model_path = models_dir / 'best_model_temp.joblib'\n",
        "joblib.dump(final_model, final_model_path)\n",
        "print(f\"✓ Modelo final salvo: {final_model_path}\")\n",
        "\n",
        "# 2. Salvar vetorizador (já existe, mas vamos garantir)\n",
        "vectorizer_final_path = models_dir / 'tfidf_vectorizer.joblib'\n",
        "joblib.dump(vectorizer, vectorizer_final_path)\n",
        "print(f\"✓ Vetorizador salvo: {vectorizer_final_path}\")\n",
        "\n",
        "# 3. Salvar label_encoder (necessário para LinearSVC)\n",
        "label_encoder_path = models_dir / 'label_encoder.joblib'\n",
        "joblib.dump(label_encoder, label_encoder_path)\n",
        "print(f\"✓ Label encoder salvo: {label_encoder_path}\")\n",
        "\n",
        "# 4. Salvar metadados\n",
        "metadata = {\n",
        "    'model_type': 'LinearSVC',\n",
        "    'model_params': final_model.get_params(),\n",
        "    'vectorizer_type': 'TfidfVectorizer',\n",
        "    'vectorizer_params': vectorizer.get_params(),\n",
        "    'training_samples': len(y_full),\n",
        "    'cv_f1_mean': float(cv_scores.mean()),\n",
        "    'cv_f1_std': float(cv_scores.std()),\n",
        "    'trained_date': datetime.now().isoformat(),\n",
        "    'features_count': X_full_tfidf.shape[1],\n",
        "    'vocabulary_size': len(vectorizer.vocabulary_),\n",
        "    'label_encoder': True,\n",
        "    'label_mapping': dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "}\n",
        "\n",
        "# Adicionar métricas do notebook 03 se disponíveis\n",
        "if tuning_results:\n",
        "    metadata.update({\n",
        "        'optimization_f1': tuning_results.get('test_f1'),\n",
        "        'optimization_accuracy': tuning_results.get('test_accuracy'),\n",
        "        'optimization_precision': tuning_results.get('test_precision'),\n",
        "        'optimization_recall': tuning_results.get('test_recall')\n",
        "    })\n",
        "\n",
        "metadata_path = models_dir / 'metadata.joblib'\n",
        "joblib.dump(metadata, metadata_path)\n",
        "print(f\"✓ Metadados salvos: {metadata_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ARTEFATOS EXPORTADOS PARA PRODUÇÃO\")\n",
        "print(\"=\"*80)\n",
        "print(\"1. best_model_temp.joblib (modelo treinado)\")\n",
        "print(\"2. tfidf_vectorizer.joblib (vetorizador TF-IDF)\")\n",
        "print(\"3. label_encoder.joblib (encoder de labels)\")\n",
        "print(\"4. metadata.joblib (informações do modelo)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusão do Pipeline Final\n",
        "\n",
        "### Modelo Final Treinado\n",
        "\n",
        "O modelo final foi treinado com 100% dos dados e validado com cross-validation.\n",
        "\n",
        "### Artefatos Exportados\n",
        "\n",
        "Todos os artefatos foram salvos em `artifacts/` e estão prontos para deploy na API:\n",
        "- `best_model_temp.joblib` - Modelo treinado\n",
        "- `tfidf_vectorizer.joblib` - Vetorizador TF-IDF\n",
        "- `metadata.joblib` - Metadados do modelo\n",
        "\n",
        "### Próximos Passos\n",
        "\n",
        "1. Executar `scripts/deploy_models.py` para copiar modelos para `api-service/models/`\n",
        "2. Testar API localmente\n",
        "3. Fazer deploy em produção\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ML Spam Classifier",
      "language": "python",
      "name": "ml-spam-classifier"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
